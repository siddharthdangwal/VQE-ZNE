{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 9 Plots ###\n",
    "\n",
    "This was the experiment where we finally got ZNE to run using the dynamic extrapolation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = '/u/vqezne/Internship/ZNE experiments/Experiment 9/'\n",
    "workload_name = 'CH4-AS4/'\n",
    "\n",
    "seeds = [0, 1, 3, 5]\n",
    "thresholds = [0, 'inf']\n",
    "\n",
    "vqe_vals_for_diff_thresholds = {}\n",
    "\n",
    "for th_idx, th_val in enumerate(thresholds):\n",
    "\n",
    "    # loss values for different seeds for a given threshold\n",
    "    running_loss = None\n",
    "    min_length = np.inf\n",
    "\n",
    "    for seed_idx, seed_val in enumerate(seeds):\n",
    "        loss_filename = parent_folder + workload_name + '/zne_th_' + str(th_val) + '_seed_' + str(seed_val) + '_losses_.csv'\n",
    "        \n",
    "        with open(loss_filename) as f:\n",
    "            csv_file = csv.reader(f)\n",
    "            loss_vals_for_seed = []\n",
    "            \n",
    "            # get all the loss values for given seed and threshold\n",
    "            for line in csv_file:\n",
    "                loss_vals_for_seed.append(float(line[0]))\n",
    "            \n",
    "            loss_vals_for_seed = np.array(loss_vals_for_seed)\n",
    "            \n",
    "            # add the loss to average out later\n",
    "            if seed_idx == 0:\n",
    "                running_loss = loss_vals_for_seed\n",
    "            else:\n",
    "                l1 = running_loss.shape[0]\n",
    "                if len(loss_vals_for_seed) < l1:\n",
    "                    l1 = len(loss_vals_for_seed)\n",
    "                \n",
    "                running_loss = np.add(running_loss[0:l1], np.array(loss_vals_for_seed[0:l1]))\n",
    "    \n",
    "    # average out across all seeds\n",
    "    running_loss = running_loss/len(seeds)\n",
    "    vqe_vals_for_diff_thresholds[th_val] = running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [0, 'inf']:#vqe_vals_for_diff_thresholds:\n",
    "    if key == 0:\n",
    "        plt.plot(list(range(len(vqe_vals_for_diff_thresholds[key]))), vqe_vals_for_diff_thresholds[key], marker = '*', label = 'zne')\n",
    "    else:\n",
    "        plt.plot(list(range(len(vqe_vals_for_diff_thresholds[key]))), vqe_vals_for_diff_thresholds[key], marker = '*', label = 'no-zne')\n",
    "plt.title('8 Qubit CH4 - ZNE vs No ZNE', fontsize = 15)\n",
    "plt.xlabel('Iteration', fontsize = 10)\n",
    "plt.ylabel('Energy', fontsize = 10)\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the parameters for the no-zne vs zne case in Experiment 9 are different or same ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = '/u/vqezne/Internship/ZNE experiments/Experiment 9/'\n",
    "workload_name = 'CH4-AS4/'\n",
    "\n",
    "seed_val = 0\n",
    "\n",
    "file_no_zne = parent_folder + workload_name + '/zne_th_inf_seed_' + str(seed_val) + '_params_.csv'\n",
    "file_with_zne = parent_folder + workload_name + '/zne_th_0_seed_' + str(seed_val) + '_params_.csv'\n",
    "\n",
    "params_no_zne = []\n",
    "params_with_zne = []\n",
    "\n",
    "with open(file_no_zne, 'r') as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        row_float = [float(x) for x in row]\n",
    "        params_no_zne.append(row_float)\n",
    "\n",
    "with open(file_with_zne, 'r') as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        row_float = [float(x) for x in row]\n",
    "        params_with_zne.append(row_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorter_length = len(params_no_zne)\n",
    "if len(params_with_zne) < shorter_length:\n",
    "    shorter_length = len(params_with_zne)\n",
    "\n",
    "inner_products = []\n",
    "for i in range(shorter_length):\n",
    "    p_no_zne = np.array(params_no_zne[i])\n",
    "    p_no_zne_normalized = p_no_zne/np.sqrt(np.inner(p_no_zne, p_no_zne))\n",
    "\n",
    "    p_wi_zne = np.array(params_with_zne[i])\n",
    "    params_with_zne_normalized = p_wi_zne/np.sqrt(np.inner(p_wi_zne, p_wi_zne))\n",
    "\n",
    "    ip = np.inner(p_no_zne_normalized, params_with_zne_normalized)\n",
    "    inner_products.append(ip)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7 plots ###\n",
    "Plots to see if not doing ZNE for earlier iterations gives us an answer which is close to doing it for all iterations or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#bmark = 'H2_6-31g_BK_0.7_AS4'\n",
    "#bmark = 'CH4_sto-3g_BK_grnd_AS4'\n",
    "#bmark = 'LiH_sto-3g_BK_1.45_AS4'\n",
    "#bmark = 'H2O_sto-3g_BK_104_AS4'\n",
    "seed = 0\n",
    "\n",
    "noise_scaling = 1\n",
    "diff_thresholds = [0, 150, 300, 700, 1200, 1800, 'inf']\n",
    "vals_at_diff_zne_thresholds = {0:[], 150:[], 300:[], 700:[], 1200:[], 1800:[], 'inf':[]}\n",
    "\n",
    "parent_folder = '/u/vqezne/Internship/ZNE experiments/Experiment 7/' + str(noise_scaling) + '/H2-AS4/'\n",
    "\n",
    "for th_idx, th_val in enumerate(diff_thresholds):\n",
    "    filename = parent_folder + 'zne_th_' + str(th_val) + '_seed_' + str(seed) + '_losses_.csv'\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            vals_at_diff_zne_thresholds[th_val].append(float(row[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "for key in vals_at_diff_zne_thresholds:\n",
    "    if key in [300, 'inf']:\n",
    "        plt.plot(list(range(len(vals_at_diff_zne_thresholds[key]))), vals_at_diff_zne_thresholds[key], marker = '*', label = str(key))\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots where we take saved parameter data and experiment with ZNE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geneeral utility\n",
    "import numpy as np\n",
    "from skquant.opt import minimize\n",
    "from scipy.stats import pearsonr\n",
    "from numpy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "# General qiskit functions\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit, ClassicalRegister, QuantumRegister, Aer, execute, IBMQ, transpile\n",
    "from qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.tools import job_monitor\n",
    "from qiskit.circuit.library import EfficientSU2\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.quantum_info import Pauli, Operator\n",
    "from qiskit.providers.models import BackendProperties\n",
    "from qiskit.providers.fake_provider import FakeMumbai\n",
    "from qiskit.compiler import transpile\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "\n",
    "# Pauli Twirling\n",
    "from qiskit_research.utils.convenience import add_pauli_twirls\n",
    "\n",
    "# ZNE\n",
    "import zne\n",
    "import mitiq\n",
    "\n",
    "# Helper functions\n",
    "from VarSaw.term_grouping import *\n",
    "import VarSaw.Reconstruction_Functions as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit a backend, the factor by which we need to scale its noise\n",
    "# returns a dictionary with the noise parameters scaled proportionately\n",
    "def alter_properties_dict(backend, scaling_factor):\n",
    "    '''\n",
    "    Args:\n",
    "    backend: The qiskit backend whose properties dictionary we have to modify\n",
    "    scaling_factor: The factor by which we want to scale the properties\n",
    "    \n",
    "    Returns:\n",
    "    A new dictionary with scaled noise parameters \n",
    "    '''\n",
    "    import copy\n",
    "    \n",
    "    conf_dict = backend.configuration().to_dict()\n",
    "    prop_dict = backend.properties().to_dict()\n",
    "    \n",
    "    new_prop_dict = copy.deepcopy(prop_dict)\n",
    "    \n",
    "    #alter the qubit based properties - readout error rates and t1, t2 times\n",
    "    qubits = prop_dict['qubits']\n",
    "    props_to_change = ['T1', 'T2', 'readout_error', 'prob_meas0_prep1', 'prob_meas1_prep0']\n",
    "    for idx, qubit in enumerate(qubits):\n",
    "        \n",
    "        #a qubit is represented by 8 properties\n",
    "        assert len(qubit) == 8\n",
    "        \n",
    "        for idx2, prop in enumerate(qubit):\n",
    "            if prop['name'] in props_to_change:\n",
    "                \n",
    "                if prop['name'] == 'T1' or prop['name'] == 'T2':\n",
    "                    new_prop_value = prop['value']*(1/scaling_factor)\n",
    "                    #print(prop['name'], prop['value'], new_prop_value)\n",
    "                else:\n",
    "                    new_prop_value = prop['value']*scaling_factor\n",
    "                    #print(prop['name'], prop['value'], new_prop_value)\n",
    "                \n",
    "                new_prop_dict['qubits'][idx][idx2]['value'] = new_prop_value\n",
    "                \n",
    "    #alter the gate based properties - gate error\n",
    "    gates = prop_dict['gates']\n",
    "    for idx, gate in enumerate(gates):\n",
    "        \n",
    "        for idx2 in range(len(gate['parameters'])):\n",
    "            \n",
    "            #a gate is represented by a dicrionary of 4 items\n",
    "            gate_error_dict = gate['parameters'][idx2]\n",
    "\n",
    "            #change the value of the gate error\n",
    "            if gate_error_dict['name'] == 'gate_error':\n",
    "                new_gate_error_val = gate_error_dict['value']*scaling_factor\n",
    "                new_prop_dict['gates'][idx]['parameters'][idx2]['value'] = new_gate_error_val\n",
    "                #print(gate_error_dict['name'], gate_error_dict['value'], new_gate_error_val)\n",
    "    \n",
    "    return new_prop_dict\n",
    "\n",
    "# Given a counts dict from VQE measurement, give the expectation for the operator\n",
    "# Assumes the necessary gates were applied to the VQE circuit to convert the \n",
    "# measurement from the operator basis to the all-Z basis.\n",
    "def compute_expectations(all_counts):\n",
    "    '''\n",
    "    Args:\n",
    "    all_counts: All the counts for which we want to compute expectations\n",
    "    \n",
    "    Returns:\n",
    "    All the expectation values\n",
    "    \n",
    "    '''\n",
    "    all_expectation_vals = []\n",
    "    for idx, count in enumerate(all_counts): \n",
    "        sum_counts = sum(list(count.values()))\n",
    "        exp_val = 0\n",
    "        for el in count:\n",
    "            \n",
    "            # allot the sign to the element\n",
    "            sign = 1\n",
    "            if el.count('1')%2 == 1:\n",
    "                sign = -1\n",
    "            \n",
    "            # add to expectation value\n",
    "            exp_val += sign*(count[el]/sum_counts)\n",
    "        \n",
    "        all_expectation_vals.append(exp_val)\n",
    "            \n",
    "    return all_expectation_vals\n",
    "\n",
    "# Given a list of Pauli oeprators and the corresponding coefficients, give the reference energy\n",
    "def get_ref_energy(coeffs, paulis):\n",
    "    '''\n",
    "    Args:\n",
    "    coeffs: The coeffs of the puali tensor products\n",
    "    paulis: The pauli tensors\n",
    "    '''   \n",
    "    # the final operation\n",
    "    final_op = None\n",
    "\n",
    "    for ii, el in enumerate(paulis):\n",
    "        if ii == 0:\n",
    "            final_op = coeffs[ii]*Operator(Pauli(el))\n",
    "        else:\n",
    "            final_op += coeffs[ii]*Operator(Pauli(el))\n",
    "   \n",
    "    # compute the eigenvalues\n",
    "    evals, evecs = eigh(final_op.data)\n",
    "   \n",
    "    # get the minimum eigenvalue\n",
    "    min_eigenval = np.min(evals)\n",
    "    return min_eigenval\n",
    "\n",
    "# Returns the Paulis and Coeffs dictionary for a particular hamiltonian\n",
    "def give_paulis_and_coeffs(hamiltonian, num_qubits):\n",
    "    '''\n",
    "    hamiltonian: A list containing all hamiltonian terms along with their weights\n",
    "    num_qubits: The number of qubits in the hamiltonian\n",
    "    '''\n",
    "    paulis = []\n",
    "    coeffs = []\n",
    "    \n",
    "    for idx, term in enumerate(hamiltonian):\n",
    "        \n",
    "        #the coefficient\n",
    "        coeffs.append(term[0])\n",
    "        \n",
    "        #the pauli string\n",
    "        pauli_string = num_qubits*'I'\n",
    "        all_gates = term[1]\n",
    "        #print(non_id_gates)\n",
    "        \n",
    "        for _, gate in enumerate(all_gates):\n",
    "            pauli = gate[0]\n",
    "            location = int(gate[1])\n",
    "            #print('location: ', location, 'pauli_string: ', pauli_string, 'pauli: ', pauli)\n",
    "            pauli_string = pauli_string[0:location] + pauli + pauli_string[location+1:]\n",
    "            #print(pauli_string, len(pauli_string))\n",
    "        \n",
    "        paulis.append(pauli_string)\n",
    "    \n",
    "    return coeffs, paulis\n",
    "\n",
    "# given an initializaed circuit and the parameters, create a quantum_state_preparation circuit\n",
    "def quantum_state_preparation(circuit, parameters):\n",
    "    '''\n",
    "    Args:\n",
    "    circuit: The input circuit to which we append the parameterized state\n",
    "    parameters: The parameters of the rotations\n",
    "    \n",
    "    Returns:\n",
    "    Circuit with /home/siddharthdangwal/JigSaw+VQE/Data/Experiment 2/TFIM-4-full/noisy_jigsaw_params.csvthe ansatz for a generalized state appended to it\n",
    "    '''\n",
    "    num_qubits = circuit.num_qubits\n",
    "    \n",
    "    #the number of repetitions of a general ansatz block\n",
    "    p = (len(parameters)/(2*num_qubits)) - 1\n",
    "    #print('Value of p is: ', p)\n",
    "    \n",
    "    #make sure that p is an integer and then change the format\n",
    "    assert int(p) == p\n",
    "    p = int(p)\n",
    "    \n",
    "    #create an EfficientSU2 ansatz\n",
    "    ansatz = EfficientSU2(num_qubits = num_qubits, entanglement = 'full', reps = p, insert_barriers = True)\n",
    "    ansatz.assign_parameters(parameters = parameters, inplace = True)\n",
    "    circuit.compose(ansatz, inplace = True)\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "# Prepare a virtual VQE circuit with the given parameters, and the given hamiltonian operator\n",
    "def vqe_circuit(n_qubits, parameters, hamiltonian):\n",
    "    '''\n",
    "    Args:\n",
    "    n_qubits: The number of qubits in the circuit\n",
    "    parameters: The parameters for the vqe circuit\n",
    "    hamiltonian: The hamiltonian string whose expectation would be measured\n",
    "    using this circuit\n",
    "    \n",
    "    Returns:\n",
    "    The VQE circuit for the given Pauli tensor hamiltonian \n",
    "    '''\n",
    "    qr = QuantumRegister(n_qubits)\n",
    "    cr = ClassicalRegister(n_qubits)\n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "    \n",
    "    #append the circuit with the state preparation ansatz\n",
    "    circuit = quantum_state_preparation(circuit, parameters)\n",
    "    \n",
    "    #add the measurement operations\n",
    "    for i, el in enumerate(hamiltonian):\n",
    "        if el == 'I':\n",
    "            #no measurement for identity\n",
    "            continue\n",
    "        elif el == 'Z':\n",
    "            circuit.measure(qr[i], cr[i])\n",
    "        elif el == 'X':\n",
    "            circuit.u(np.pi/2, 0, np.pi, qr[i])\n",
    "            circuit.measure(qr[i], cr[i])\n",
    "        elif el == 'Y':\n",
    "            circuit.u(np.pi/2, 0, np.pi/2, qr[i])\n",
    "            circuit.measure(qr[i], cr[i])\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "# Given \n",
    "# 1) a list of digital ZNE scaled ansatz (without measurement operations) which are mapped to the hardware\n",
    "# 2) A Pauli operator\n",
    "# 3) The virtual - to - physcial mapping for the scaled ansayz\n",
    "\n",
    "# Apply the required gates and measurement operations so that we can measure the expectation of the given\n",
    "# Pauli operator\n",
    "def apply_operator(all_scaled_ansatz, pauli_op, layout_dict):\n",
    "    '''\n",
    "    Args:\n",
    "    all_scaled_ansatz: A list of ansatz scaled at different noise factors\n",
    "    pauli_op: The Pauli operator whose expectation we want to obtain\n",
    "    layout_dict: The mapping from virtual to physical done on the ansatz\n",
    "    '''\n",
    "    ansatz_with_measurement = []\n",
    "    for idx, ansatz in enumerate(all_scaled_ansatz):\n",
    "        \n",
    "        # apply all the operations to change basis on the ansatz\n",
    "        for pauli_idx, pauli in enumerate(pauli_op):\n",
    "            if pauli == 'I':\n",
    "                continue\n",
    "            elif pauli == 'Z':\n",
    "                ansatz.measure(layout_dict[pauli_idx], pauli_idx)\n",
    "            elif pauli == 'X':\n",
    "                ansatz.rz(np.pi/2, layout_dict[pauli_idx])\n",
    "                ansatz.sx(layout_dict[pauli_idx])\n",
    "                ansatz.rz(np.pi/2, layout_dict[pauli_idx])\n",
    "                ansatz.measure(layout_dict[pauli_idx], pauli_idx)\n",
    "            elif pauli == 'Y':\n",
    "                ansatz.sx(layout_dict[pauli_idx])\n",
    "                ansatz.rz(np.pi/2, layout_dict[pauli_idx])\n",
    "                ansatz.measure(layout_dict[pauli_idx], pauli_idx)\n",
    "        \n",
    "        # add this circuit to the list of circuits with measurements\n",
    "        ansatz_with_measurement.append(ansatz)\n",
    "    \n",
    "    return ansatz_with_measurement\n",
    "\n",
    "# Performs the expectation calculation step for VQE. The flag 'zne_flag' controls whether\n",
    "# we report a zero-noise-extrapolated value or just a noisy value\n",
    "def compute_expectations_perfect_simulation(parameters, paulis, backend, scales, nm_scaling_factor, zne_flag = False, noise_model_flag = True):\n",
    "    '''\n",
    "    Args:\n",
    "    parameters: The parameters for the VQE ansatz\n",
    "    paulis: Pauli strings that make up the VQE hamiltonian\n",
    "    backend: The backend on which the vqe is run\n",
    "    scales: The different scales at which the noise has to be scaled\n",
    "    nm_scaling_factor: The scale by which we should scale the noise in the backend\n",
    "    noise_model_flag: If True we run noisy simulations, else we run ideal simulations\n",
    "    \n",
    "    Returns:\n",
    "    A list of expectations for each circuit\n",
    "    '''\n",
    "    \n",
    "    global scaled_exp_dict_for_diff_iterations\n",
    "    global iter_num\n",
    "    \n",
    "    #the number of qubits\n",
    "    n_qubits = len(paulis[0])\n",
    "    \n",
    "    #get the ansatz\n",
    "    qr = QuantumRegister(n_qubits)\n",
    "    cr = ClassicalRegister(n_qubits)\n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "    ansatz = quantum_state_preparation(circuit, parameters)\n",
    "    \n",
    "    # transpile the ansatz -- assuming all-to-all connectivity\n",
    "    backend_basis_gates = backend.configuration().basis_gates\n",
    "    transpiled_ansatz = transpile(ansatz, basis_gates = backend_basis_gates, optimization_level = 3, seed_transpiler = 0)\n",
    "\n",
    "    # twirl the ansatz\n",
    "    # twirled_ansatz  = add_pauli_twirls(transpiled_ansatz, num_twirled_circuits = 10, seed = 0, transpile_added_paulis = True)\n",
    "    twirled_ansatz = [transpiled_ansatz]\n",
    "    \n",
    "    # get noise extrapolated versions of the transpiled ansatz\n",
    "    # add function to record state\n",
    "    all_scaled_ansatz = {}\n",
    "\n",
    "    # if the zne flag is true then\n",
    "    if zne_flag:\n",
    "        for scale_val in scales:\n",
    "            #scaled_ansatz_for_scale_val = mitiq.zne.scaling.folding.fold_gates_from_left(transpiled_ansatz, scale_val)\n",
    "            scaled_ansatz_for_scale_val = [mitiq.zne.scaling.folding.fold_all(c, scale_val, exclude = frozenset({\"single\"})) for c in twirled_ansatz]\n",
    "            for el in scaled_ansatz_for_scale_val:\n",
    "                el.save_state()\n",
    "            all_scaled_ansatz[scale_val] = scaled_ansatz_for_scale_val\n",
    "    else:\n",
    "        # if zne flag is false, we just need to run one circuit\n",
    "        scaled_ansatz_for_scale_val = copy.deepcopy(transpiled_ansatz)\n",
    "        scaled_ansatz_for_scale_val.save_state()\n",
    "        all_scaled_ansatz['default'] = scaled_ansatz_for_scale_val # only one circuit -- no twirling or folding needed\n",
    "    \n",
    "    # simulate the ansatz and compute expectations using noisy simulator and ideally to get the expectation value\n",
    "    #print('noise_model_flag: ', noise_model_flag)\n",
    "    if noise_model_flag:\n",
    "        #print('Entered!')\n",
    "        scaled_props_dict = alter_properties_dict(backend = backend, scaling_factor = nm_scaling_factor)\n",
    "        scaled_props = BackendProperties.from_dict(scaled_props_dict)\n",
    "        noise_model = NoiseModel.from_backend_properties(scaled_props)\n",
    "    simulator_dm = Aer.get_backend('aer_simulator_density_matrix', max_parallel_experiments = 0)\n",
    "    \n",
    "    # compute expectations and store them\n",
    "    estimated_expectation_vals = []\n",
    "\n",
    "    if not zne_flag:\n",
    "        relevant_circuit = all_scaled_ansatz['default']\n",
    "\n",
    "        if noise_model_flag:\n",
    "            job = simulator_dm.run(relevant_circuit, noise_model = noise_model)\n",
    "        else:\n",
    "            job = simulator_dm.run(relevant_circuit)\n",
    "        \n",
    "        relevant_dm = job.result().data(relevant_circuit)['density_matrix'].data\n",
    "        for pauli_idx, pauli_op in enumerate(paulis):\n",
    "            pauli_op_data = Operator(Pauli(pauli_op)).data\n",
    "            exp_val = np.trace(np.matmul(relevant_dm, pauli_op_data))\n",
    "            estimated_expectation_vals.append(exp_val.real)\n",
    "        \n",
    "        iter_num += 1\n",
    "        return estimated_expectation_vals\n",
    "    \n",
    "    else:\n",
    "        all_scaled_ansatz_list = []\n",
    "        for el in all_scaled_ansatz:\n",
    "            all_scaled_ansatz_list += all_scaled_ansatz[el]\n",
    "\n",
    "        if noise_model_flag:    \n",
    "            job = simulator_dm.run(all_scaled_ansatz_list, noise_model = noise_model)\n",
    "        else:\n",
    "            job = simulator_dm.run(all_scaled_ansatz_list)\n",
    "        \n",
    "        length_per_scale_val = len(all_scaled_ansatz_list)/len(scales)\n",
    "        assert (int(length_per_scale_val) == length_per_scale_val)\n",
    "        length_per_scale_val = int(length_per_scale_val)\n",
    "\n",
    "        for pauli_idx, pauli_op in enumerate(paulis):\n",
    "            pauli_op_data = Operator(Pauli(pauli_op)).data\n",
    "            \n",
    "            # get the different scaled expectation values for the given Pauli operator\n",
    "            scaled_exp_vals_for_pauli_op = []\n",
    "            \n",
    "            for scale_idx, scale_val in enumerate(scales):\n",
    "                relevant_circuits = all_scaled_ansatz[scale_val]\n",
    "                exp_val = 0\n",
    "                for cc in relevant_circuits:\n",
    "                    relevant_dm = job.result().data(cc)['density_matrix'].data\n",
    "                    exp_val += np.trace(np.matmul(relevant_dm, pauli_op_data))\n",
    "                exp_val = exp_val/len(relevant_circuits)\n",
    "                scaled_exp_vals_for_pauli_op.append(exp_val)\n",
    "            \n",
    "            estimated_expectation_val = scaled_exp_vals_for_pauli_op[0]\n",
    "            exp_extrapolation_factory = mitiq.zne.inference.ExpFactory(scale_factors = scales)\n",
    "            lin_extrapolation_factory = mitiq.zne.inference.LinearFactory(scale_factors = scales)\n",
    "            \n",
    "            try:\n",
    "                exp_estimated_expectation_val = exp_extrapolation_factory.extrapolate(scale_factors = scales, exp_values = scaled_exp_vals_for_pauli_op)\n",
    "                lin_estimated_expectation_val = lin_extrapolation_factory.extrapolate(scale_factors = scales, exp_values = scaled_exp_vals_for_pauli_op)\n",
    "\n",
    "                if abs(exp_estimated_expectation_val) <= 5*abs(lin_estimated_expectation_val):\n",
    "                    estimated_expectation_val = exp_estimated_expectation_val\n",
    "                else:\n",
    "                    estimated_expectation_val = lin_estimated_expectation_val\n",
    "            except:\n",
    "                lin_estimated_expectation_val = lin_extrapolation_factory.extrapolate(scale_factors = scales, exp_values = scaled_exp_vals_for_pauli_op)\n",
    "                estimated_expectation_val = lin_estimated_expectation_val\n",
    "\n",
    "            # record the ZNE estimated value, and the baseline noisy value too\n",
    "            estimated_expectation_vals.append(estimated_expectation_val.real)\n",
    "    \n",
    "        # save the scaled expectations dict\n",
    "        #scaled_exp_dict_for_diff_iterations[iter_num] = scaled_exps_dict\n",
    "        iter_num += 1\n",
    "\n",
    "        return estimated_expectation_vals\n",
    "\n",
    "# Given parameters, paulis, and coefficients, the function computes the VQE loss\n",
    "# Calls the 'compute_expectations_perfect_simulation' function\n",
    "def compute_loss_perfect_simulation(parameters, coeffs, zne_threshold, **kwargs):\n",
    "    '''\n",
    "    Args:\n",
    "    parameters: The parameters for the VQE ansatz\n",
    "    paulis: Pauli strings that make up the VQE hamiltonian\n",
    "    coeffs: Coefficients corresponding to Paulis\n",
    "    backend: The backend on which the vqe is run\n",
    "    scales: The different scales at which the noise has to be scaled\n",
    "    nm_scaling_factor: The scale by which we should scale the noise in the backend\n",
    "    \n",
    "    Returns:\n",
    "    The loss for the entire VQE hamiltonian\n",
    "    '''\n",
    "    global iter_num\n",
    "    \n",
    "    # if the iteration number crosses a threshold, then start applying ZNE\n",
    "    if iter_num < zne_threshold:\n",
    "        expectations = compute_expectations_perfect_simulation(parameters, **kwargs)\n",
    "    else:\n",
    "        expectations = compute_expectations_perfect_simulation(parameters, zne_flag = True, **kwargs)\n",
    "    \n",
    "    loss = 0\n",
    "    for i, el in enumerate(expectations):\n",
    "        loss += coeffs[i]*el\n",
    "    return loss\n",
    "\n",
    "# Computes the loss, and saves it in the given files. Calls the 'compute_loss_perfect_simulation' function internally\n",
    "def vqe_perfect_simulation(parameters, loss_filename = None, params_filename = None, **kwargs):\n",
    "    '''\n",
    "    Args:\n",
    "    parameters: The parameters of the VQE ansatz\n",
    "    paulis: The paulis tensor hamiltonians\n",
    "    coeffs: The coefficients corresponding to each pauli tensor\n",
    "    backend: The backend on which the vqe is run\n",
    "    mode: Specifies if we have to run a noisy simulation or ideal simulation or run the circuit on a device\n",
    "    shots: The number of shots for which each circuit is executed\n",
    "    \n",
    "    Returns:\n",
    "    Loss for one iteration of the VQE\n",
    "    '''\n",
    "\n",
    "    #number of qubits in the VQE ansatz\n",
    "    paulis = kwargs['paulis']\n",
    "    n_qubits = len(paulis[0])\n",
    "    \n",
    "    #making sure that the number of elements in each pauli tensor is the same\n",
    "    for i in paulis:\n",
    "        assert len(i) == n_qubits\n",
    "    \n",
    "    loss =  compute_loss_perfect_simulation(parameters, **kwargs)\n",
    "    print('Loss computed by VQE is: {}'.format(loss))\n",
    "    \n",
    "    # save the loss and parameters\n",
    "    if not (loss_filename == None):\n",
    "        with open(loss_filename, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([loss])\n",
    "    \n",
    "    if not(params_filename == None):\n",
    "        with open(params_filename, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(parameters)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions which give the loss value at all the different scale values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_at_diff_scales(parameters, paulis, coeffs, backend, scales, nm_scaling_factor):\n",
    "    '''\n",
    "    Args:\n",
    "\n",
    "    '''\n",
    "    #the number of qubits\n",
    "    n_qubits = len(paulis[0])\n",
    "    \n",
    "    #get the ansatz\n",
    "    qr = QuantumRegister(n_qubits)\n",
    "    cr = ClassicalRegister(n_qubits)\n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "    ansatz = quantum_state_preparation(circuit, parameters)\n",
    "    \n",
    "    # transpile the ansatz -- assuming all-to-all connectivity\n",
    "    backend_basis_gates = backend.configuration().basis_gates\n",
    "    transpiled_ansatz = transpile(ansatz, basis_gates = backend_basis_gates, optimization_level = 3, seed_transpiler = 0)\n",
    "\n",
    "    # twirl the ansatz\n",
    "    # twirled_ansatz  = add_pauli_twirls(transpiled_ansatz, num_twirled_circuits = 10, seed = 0, transpile_added_paulis = True)\n",
    "    twirled_ansatz = [transpiled_ansatz]\n",
    "    \n",
    "    # get noise extrapolated versions of the transpiled ansatz\n",
    "    # add function to record state\n",
    "    all_scaled_ansatz = {}\n",
    "\n",
    "    for scale_val in scales:\n",
    "        #scaled_ansatz_for_scale_val = mitiq.zne.scaling.folding.fold_gates_from_left(transpiled_ansatz, scale_val)\n",
    "        scaled_ansatz_for_scale_val = [mitiq.zne.scaling.folding.fold_all(c, scale_val, exclude = frozenset({\"single\"})) for c in twirled_ansatz]\n",
    "        for el in scaled_ansatz_for_scale_val:\n",
    "            el.save_state()\n",
    "        all_scaled_ansatz[scale_val] = scaled_ansatz_for_scale_val\n",
    "\n",
    "    # simulate the ansatz and compute expectations using noisy simulator and ideally to get the expectation value\n",
    "    \n",
    "    scaled_props_dict = alter_properties_dict(backend = backend, scaling_factor = nm_scaling_factor)\n",
    "    scaled_props = BackendProperties.from_dict(scaled_props_dict)\n",
    "    noise_model = NoiseModel.from_backend_properties(scaled_props)\n",
    "    simulator_dm = Aer.get_backend('aer_simulator_density_matrix', max_parallel_experiments = 0)\n",
    "    \n",
    "    # represent all scaled ansatz as a list\n",
    "    estimated_expectation_vals = []\n",
    "    all_scaled_ansatz_list = []\n",
    "    for el in all_scaled_ansatz:\n",
    "        all_scaled_ansatz_list += all_scaled_ansatz[el]\n",
    "    \n",
    "    # for ideal simulation, we just need the baseline ansatz\n",
    "    all_ansatz_for_ideal_sim = all_scaled_ansatz[1]\n",
    "   \n",
    "    # run the noisy simulation and noiseless simulation \n",
    "    job_noisy = simulator_dm.run(all_scaled_ansatz_list, noise_model = noise_model)\n",
    "    job_ideal = simulator_dm.run(all_scaled_ansatz_list)\n",
    "    \n",
    "    length_per_scale_val = len(all_scaled_ansatz_list)/len(scales)\n",
    "    assert (int(length_per_scale_val) == length_per_scale_val)\n",
    "    length_per_scale_val = int(length_per_scale_val)\n",
    "\n",
    "    scaled_exp_vals_for_all_paulis = {}\n",
    "\n",
    "    for pauli_idx, pauli_op in enumerate(paulis):\n",
    "        pauli_op_data = Operator(Pauli(pauli_op)).data\n",
    "        \n",
    "        # get the different scaled expectation values for the given Pauli operator\n",
    "        scaled_exp_vals_for_pauli_op = []\n",
    "        \n",
    "        for scale_idx, scale_val in enumerate(scales):\n",
    "            relevant_circuits = all_scaled_ansatz[scale_val]\n",
    "            exp_val = 0\n",
    "            for cc in relevant_circuits:\n",
    "                relevant_dm = job_noisy.result().data(cc)['density_matrix'].data\n",
    "                exp_val += np.trace(np.matmul(relevant_dm, pauli_op_data))\n",
    "            exp_val = exp_val/len(relevant_circuits)\n",
    "            scaled_exp_vals_for_pauli_op.append(exp_val)\n",
    "        \n",
    "        scaled_exp_vals_for_all_paulis[pauli_op] = scaled_exp_vals_for_pauli_op\n",
    "\n",
    "    loss_at_diff_scales = []\n",
    "    for scale_idx, scale_val in enumerate(scales):\n",
    "        loss_at_scale = 0\n",
    "        for pauli_idx, pauli_op in enumerate(paulis):\n",
    "            loss_at_scale += coeffs[pauli_idx]*scaled_exp_vals_for_all_paulis[pauli_op][scale_idx].real\n",
    "        loss_at_diff_scales.append(loss_at_scale)\n",
    "    \n",
    "    ideal_loss_value = 0\n",
    "    for pauli_idx, pauli_op in enumerate(paulis):\n",
    "        pauli_op_data = Operator(Pauli(pauli_op)).data\n",
    "\n",
    "        # get the expectation value for the given pauli operator\n",
    "        relevant_circuits = all_ansatz_for_ideal_sim\n",
    "        exp_val = 0\n",
    "        for cc in relevant_circuits:\n",
    "            relevant_dm = job_ideal.result().data(cc)['density_matrix'].data\n",
    "            exp_val += np.trace(np.matmul(relevant_dm, pauli_op_data))\n",
    "        exp_val = exp_val/len(relevant_circuits)\n",
    "        ideal_loss_value += coeffs[pauli_idx]*exp_val\n",
    "        \n",
    "    return ideal_loss_value, loss_at_diff_scales\n",
    "\n",
    "def get_distance(l1, l2):\n",
    "    '''\n",
    "    Args:\n",
    "    l1: List of energy values that comprise curve 1\n",
    "    l2: List of energy values that comprise curve 2\n",
    "\n",
    "    Returns:\n",
    "    Distance between the l1 and l2 curves which we define as the \n",
    "\n",
    "    '''\n",
    "    distance = 0\n",
    "    for idx, el in enumerate(l1):\n",
    "        diff = abs(el - l2[idx])\n",
    "        distance += 0.5*(abs(diff/el) + abs(diff/l2[idx]))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first argument is the molecule test file\n",
    "molecule_string = 'CH4_sto-3g_BK_grnd_AS4' # write molecule name here\n",
    "#bmark = 'H2_6-31g_BK_0.7_AS4'\n",
    "#bmark = 'CH4_sto-3g_BK_grnd_AS4'\n",
    "#bmark = 'LiH_sto-3g_BK_1.45_AS4'\n",
    "#bmark = 'H2O_sto-3g_BK_104_AS4'\n",
    "\n",
    "\n",
    "hamiltonian_string = '/u/vqezne/Internship/VarSaw/vqe-term-grouping-master/hamiltonians/' + molecule_string + '.txt'\n",
    "hamiltonian_string_elements = hamiltonian_string.split('/')\n",
    "hamil = parseHamiltonian(hamiltonian_string)\n",
    "\n",
    "#get the number of qubits in the hamiltonian\n",
    "max_length = 0\n",
    "for i in hamil:\n",
    "    if int(i[1][-1][1]) + 1 > max_length:\n",
    "        max_length = int(i[1][-1][1]) + 1\n",
    "\n",
    "#Number of qubits in the hamiltonian\n",
    "n_qubits = max_length\n",
    "\n",
    "# number of repetitions\n",
    "p = 1\n",
    "\n",
    "#get paulis and coefficients\n",
    "coeffs, paulis = give_paulis_and_coeffs(hamil, n_qubits)\n",
    "n_terms = len(paulis)\n",
    "paulis = paulis[1:n_terms]\n",
    "coeffs = coeffs[1:n_terms]\n",
    "\n",
    "# set the computation seed\n",
    "seed = 0\n",
    "qiskit.utils.algorithm_globals.random_seed = int(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = '/u/vqezne/Internship/ZNE experiments/Experiment 8/'\n",
    "workload_name = 'CH4-AS4/'\n",
    "\n",
    "seed_val = 1\n",
    "\n",
    "file_no_zne = parent_folder + workload_name + '/zne_th_inf_seed_' + str(seed_val) + '_params_.csv'\n",
    "file_with_zne = parent_folder + workload_name + '/zne_th_0_seed_' + str(seed_val) + '_params_.csv'\n",
    "\n",
    "file_loss_no_zne = parent_folder + workload_name + '/zne_th_inf_seed_' + str(seed_val) + '_losses_.csv'\n",
    "file_loss_with_zne = parent_folder + workload_name + '/zne_th_0_seed_' + str(seed_val) + '_losses_.csv'\n",
    "\n",
    "params_no_zne = []\n",
    "params_with_zne = []\n",
    "\n",
    "loss_no_zne = []\n",
    "loss_with_zne = []\n",
    "\n",
    "with open(file_no_zne, 'r') as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        row_float = [float(x) for x in row]\n",
    "        params_no_zne.append(row_float)\n",
    "\n",
    "with open(file_with_zne, 'r') as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row in csv_file:\n",
    "        row_float = [float(x) for x in row]\n",
    "        params_with_zne.append(row_float)\n",
    "\n",
    "with open(file_loss_no_zne, 'r') as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row_idx, row in enumerate(csv_file):\n",
    "        if row_idx%100 == 0:\n",
    "            loss_no_zne.append(float(row[0]))\n",
    "\n",
    "with open(file_loss_with_zne, 'r') as f:\n",
    "    csv_file = csv.reader(f)\n",
    "    for row_idx, row in enumerate(csv_file):\n",
    "        if row_idx%100 == 0:\n",
    "            loss_with_zne.append(float(row[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for the following ###\n",
    "1. No ZNE training\n",
    "2. No ZNE training - ZNE inference\n",
    "3. ZNE trainging\n",
    "4. ZNE trainging - ZNE inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_no_zne_ideal = []\n",
    "loss_zne_only_inf = []\n",
    "loss_with_zne_ideal = []\n",
    "loss_zne_opt_and_inf = []\n",
    "\n",
    "backend = FakeMumbai()\n",
    "global iter_num\n",
    "\n",
    "# First - No ZNE, ideal sim\n",
    "print('First')\n",
    "kwargs1 = {\n",
    "    'paulis': paulis,\n",
    "    'backend': backend,\n",
    "    'scales': None,\n",
    "    'nm_scaling_factor': None,\n",
    "    'noise_model_flag': False\n",
    "}\n",
    "iter_num = 0\n",
    "for params_idx, params_val in enumerate(params_no_zne):\n",
    "    if params_idx%100 == 0:\n",
    "        loss = compute_loss_perfect_simulation(params_val, coeffs, np.inf, **kwargs1)\n",
    "        loss_no_zne_ideal.append(loss) \n",
    "\n",
    "# Second - ZNE, ideal sim\n",
    "print('Second')\n",
    "kwargs2 = {\n",
    "    'paulis': paulis,\n",
    "    'backend': backend,\n",
    "    'scales': None,\n",
    "    'nm_scaling_factor': None,\n",
    "    'noise_model_flag': False\n",
    "}\n",
    "iter_num = 0\n",
    "for params_idx, params_val in enumerate(params_with_zne):\n",
    "    if params_idx%100 == 0:\n",
    "        loss = compute_loss_perfect_simulation(params_val, coeffs, np.inf, **kwargs2)\n",
    "        loss_with_zne_ideal.append(loss)\n",
    "\n",
    "# Third - ZNE only at inference, noisy sim\n",
    "print('Third')\n",
    "kwargs3 = {\n",
    "    'paulis': paulis,\n",
    "    'backend': backend,\n",
    "    'scales': [1, 3, 5],\n",
    "    'nm_scaling_factor': 8,\n",
    "    'noise_model_flag': True\n",
    "}\n",
    "iter_num = 0\n",
    "for params_idx, params_val in enumerate(params_no_zne):\n",
    "    if params_idx%100 == 0:\n",
    "        loss = compute_loss_perfect_simulation(params_val, coeffs, 0, **kwargs3)\n",
    "        loss_zne_only_inf.append(loss)\n",
    "\n",
    "# # Fourth - ZNE during opt and inference, noisy sim\n",
    "# print('Fourth')\n",
    "# kwargs4 = {\n",
    "#     'paulis': paulis,\n",
    "#     'backend': backend,\n",
    "#     'scales': [1, 3, 5],\n",
    "#     'nm_scaling_factor': 8,\n",
    "#     'noise_model_flag': True\n",
    "# }\n",
    "# iter_num = 0\n",
    "# for params_idx, params_val in enumerate(params_with_zne):\n",
    "#     if params_idx%100 == 0:\n",
    "#         loss = compute_loss_perfect_simulation(params_val, coeffs, 0, **kwargs4)\n",
    "#         loss_zne_opt_and_inf.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(range(len(loss_no_zne))), loss_no_zne, label = 'loss-no-zne-noisy', marker = '*')\n",
    "plt.plot(list(range(len(loss_with_zne))), loss_with_zne, label= 'loss-with-zne-noisy', marker = '*')\n",
    "plt.plot(list(range(len(loss_no_zne_ideal))), loss_no_zne_ideal, label = 'loss-no-zne-ideal', marker = '*')\n",
    "plt.plot(list(range(len(loss_with_zne_ideal))), loss_with_zne_ideal, label = 'loss-with-zne-ideal', marker = '*')\n",
    "plt.plot(list(range(len(loss_zne_only_inf))), loss_zne_only_inf, label = 'loss-with-zne-noisy-only-inf', marker = '*')\n",
    "#plt.plot(list(range(len(loss_zne_opt_and_inf))), loss_zne_opt_and_inf, label = 'loss-with-zne-noisy-opt-and-inf', marker = '*')\n",
    "plt.legend(bbox_to_anchor = (1, 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisy_sim_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
